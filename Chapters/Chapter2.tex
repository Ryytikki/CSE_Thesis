\chapter{Radiative Transfer in GASOLINE}

\section{Reverse Ray Tracing}

Reverse ray tracing is a method similar to standard (or forward) ray tracing but instead of tracing rays from each source through the simulation we instead trace rays from the sink outwards into the system, interacting with sources. This allows us to only trace rays where required, avoiding the issue shown in figure \ref{rayfig}. This also has the benefit of allowing us to take advantage of the tree structure by merging distant sources together into a single source, substantially reducing the computational cost. 

Probably the most important advantage is that we only perform the source walk for active sink particles. This way we can use adaptive time stepping and the amount of radiation work scales linearly with the size of the active subset, just as for gravity and hydrodynamics. Thus, we retain the advantages of adaptive time stepping, giving a wall-clock speed-up of order 100 times for gravity and hydro.

Reverse ray tracing doesn't suffer the issue of over or under-sampling of rays based on the position of a source in the system seen in forward ray tracing due each sink tracing a set number of rays from itself, with the quantity being either predetermined or based on refinement criterion. Thus there are no Monte Carlo errors in the flux associated with forward ray tracing. Further optimization such as ignoring sources with minimal flux contribution can also be utilized, something that is impossible to do with forward ray tracing codes due to not knowing the full list of sources a sink interacts with until the full ray trace has been completed.

Other minor advantages include knowing the distance to the sink when we walk. This allows us to use the light travel time to take into account the correct age of the source and apply red-shift corrections or spectral changes due to absorption.

\section{Existing Reverse Raytracing codes}

\subsection{TreeCol}
\label{sec:healpix}
TreeCol \citep{treecol} utilizes reverse ray tracing to produce a spherical column density map of the system for each sink particle  through information stored in the gravity tree. This is calculated during the gravity walk, minimizing the amount of communication required between sections of the tree stored on different CPUs. Originally implemented in the GADGET code \citep{gadget}, it uses an oct-tree as the basis for its tree walk.

The HEALPix algorithm is used to calculate the starting directions of the rays. HEALPix is a method for partitioning a sphere into ``pixels" of equal area \citep{healpix}. Utilizing such pixels guarantees that the sky around each sink is fully and equally sampled as all rays will subtend a roughly equal solid angle in the sky. Additionally, increasing the pixel number increases the angular resolution everywhere on the sphere by an equal amount. Latitude-longitude discretisation methods suffer from higher angular resolution of pixels at the poles and thus do not gain this benefit.

Each ray is traced from the sink to the edge of the system. At each node that passes the refinement criterion, the absorption properties are ``smeared" across the node and the node's contribution to absorption is calculated. For nodes whose bounds are only partially intersected by the cell, only the fraction of the cell that intersects contributes. Particle level refinement is performed by projecting the SPH particles as squares in the sky who's side lengths $r_n$ are calculated to give an area equal to that of a circle of radius equal to the smoothing length $h$ such that,
\begin{equation}
    r_n = \frac{1}{2} \sqrt{\pi}h.
\end{equation}
A square profile is selected over the standard circular one due to the computational complexity of calculating the ``true" fraction of the SPH particle that intersects with the HEALPix pixel as the pixel and particle have quite differing shapes. This would require numerical integration over the overlapping areas and would still only give an approximate value.

\subsection{URCHIN}

URCHIN \citep{urchin} is a reverse ray tracing scheme designed to model self-shielding from post-reionization UV background radiation in cosmological simulations. Instead of utilizing a binary tree, URCHIN traces a fixed number of rays (by default 12) from each sink and interacts directly with the resolution elements (be it SPH, mesh, etc) that the ray intersects. The direction of each ray is once again selected through the use of a HEALPix sphere and no refinement process is applied. Instead optimization is gained by treating all particles outside self-shielded and proximity zones as correct in the uniform, optically thin limit. Reverse ray tracing was selected over forward ray tracing due to the greater accuracy when modelling background sources, uniform sampling of sources and the ability to sample a broad range of spectral bands.

To begin, the neutral fraction of each particle is set to its optically thick value, allowing for the H1 column density to be calculated along each ray. The shielded photoionization rate is then calculated (see \citealt{urchin}) along with an effective optical depth. Resolution elements whose effective optical depths are below a set threshold are treated as optically thin for subsequent iterations. All other elements are iterated over until the change in neutral fraction is within acceptable bounds and thus the elements are treated as converged. For typical values, this convergence occurs within 5 iterations for 99\% of elements.

\subsection{TreeRay}

TreeRay \citep{treeRay} was developed for the FLASH AMR code \citep{flash} to model ionizing radiation from massive stars. TreeRay takes advantage of the preexisting gravity oct-tree in FLASH, once again tracing a multitude of rays around each sink who's directions are calculated using a HEALPix sphere. Each ray is split into multiple segments with lengths increasing linearly as you move away from the target cell. This causes the segment lengths to approximately correspond to the physical size of the nodes that pass refinement.

During the tree traversal, the contribution of each node to the ray segments is calculated by mapping the densities, radiation luminosities and energy fluxes according to the amount that the ray intersects the node volume. Once the walk is complete, the 1D radiative transport equation is solved along each ray, along with physical properties such as the Str{\"o}mgren radius and the recombination rate (see \citep{treeRay}). By drawing a fixed number of rays from each source, the computational cost of this algorithm is independent of the number of sources, allowing for the simulation of radiative feedback of many stars.

\section{GASOLINE}

GASOLINE \citep{gasoline} is an N-body Smoothed Particle Hydrodynamics (SPH) code developed to simulate astrophysical hydrodynamics with self-gravity Separate trees are built for all components of the system (e.g. gravity, SPH, radiation), allowing for data from previous components (such as density from SPH) to be used in the first tree builds but adding to the overhead of each step. When GASOLINE was developed, the ratio of time spent running computation to time spent building the tree to was more than 100:1, making the added computational cost of multiple tree builds negligible \citep{rory}. This is no longer true with adaptive timestepping for the dynamical ranges achieved currently and motivated design changes for ChaNGa as discussed in Chapter \ref{sec:ChaNGa}.

As GASOLINE is built upon PKDGrav \citep{pkdgrav}, a N-body gravity code, SPH was the most applicable method for hydrodynamics. Refer to \citet{wadsley2017} for a current description of the physical models, algorithms and code performance on tests. 

\subsection{Tree Codes}

Originally outlined in \cite{gravity}, data trees can be utilized to drastically reduce the computational cost of calculating gravitational forces. Existing N-Body methods at the time mainly relied on directly calculating the force between every particle pair, resulting in a cost of $\mathcal{O}(N^2)$ where N is the baryon count of the system. By splitting the simulation volume into a tree of nested boxes, or nodes, each containing combined physical properties such as the total and centre of mass of their children, we can treat entire nodes as single sources. This process is repeated until either only one particle remains in the node or in some cases until under a set number of particles remain.

Unfortunately, nodes higher in the tree act as a poorer estimate of the true particle properties and thus create larger errors in the gravitational force. Because of this we require a criterion for deciding if a node should be opened. The method developed by Barnes and Hut was to take the maximum dimension of the node being considered and divide it by the distance between that node's centre of mass and the particle being walked. If this value is greater than a chosen ``opening angle", the angular size of the node in the sky as seen by the particle is too great and the node is refined. Otherwise, the node is considered to be an accurate representation of the constituent particles and can be used to calculate their contribution to the gravitational force. This substantially reduces the number of calculations required, giving a cost of $\mathcal{O}(N \log(N))$ where N is the number of particles (assumed to be proportional to the number of tree nodes. 

One method utilized by Barnes and Hut to reduce the error caused by the opening angle is to implement a multipole expansion. In their case, they used a quadrupole expansion causing the first error term to be $\mathcal{O}(dx^3)$ where $dx$ is the physical size of the node being expanded. Higher order expansions give smaller error terms and thus allow for a larger opening angle to be used while retaining a given error. GASOLINE utilizes a hexadecapole expansion for gravity, giving it a leading error term of $\mathcal{O}(dx^5)$. this gives better than 1\% errors for an opening angle of 0.7. TREVR, on the other hand, is monopole, giving a leading error term of $\mathcal{O}(dx^2)$, requiring a smaller opening angle for the same error.

There are several ways that the simulation volume can be split. The first is with an oct-tree, where each node is split into 8 equally sized sub-nodes by equally bisecting the node in all three dimensions. Alternatively, one can bisect in only one dimension at each level creating a k-d tree. Equally bisecting at each level effectively simulates an oct-tree every 3 levels.

\section{The TREVR Radiative Transfer Method}

Designed and implemented in the GASOLINE SPH code by Rory Woods, James Wadsley and Hugh Couchman \citep{rory} and expanded upon by Jasper Grond \citep{grond}, TREVR (Tree-based REVerse Raytrace) is an adaptive radiative transfer scheme that can be applied to both SPH and grid-based codes. By walking from the sink to the source we utilize a tree similar to the gravitational force computation, combining distant sources to reduce computational cost. In TREVR, we trace exactly one ray between each sink-source pair, where the source can be either an individual star particle or a combined source node. This gives a computational cost for the optically thin regime of $\mathcal{O}(N_{sink}Log(N_{source}))$.

To calculate optical depths TREVR utilizes a tree, combining absorbers where the loss in accuracy is within acceptable bounds as described in section \ref{sec:sourceRef}. TREVR uses a similar method for the optically thick walk, combining nodes whose absorption properties give a good approximation of their component absorbing particles. This is described in detail in section \ref{sec:thickRefine}. The optical depth of the ray is computed at each step in the walk by calculating the length of the ray segment passing through the node's bounding box which is combined with its averaged absorption properties.

While the utilization of a tree makes this algorithm suitable for a grid code, some form of SPH-like approach must be implemented for the ``last mile", where refinement to the individual absorbing particles is required. Failure to do this can cause incorrect results for such things as the propagation of ionization fronts. This was convenient when developing TREVR as the existing SPH code could be utilized for the particle level ray tracing. TREVR controls refinement in the radiation code by utilizing an opening angle criterion while searching for sources (see section \ref{sec:sourceRef}) and refines based on the maximum optical depth variation of the node for the optically thick walk (see section \ref{sec:thickRefine}). 